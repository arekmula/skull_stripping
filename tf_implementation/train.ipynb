{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skull_train",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwuswiM6l_-l"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj5rI8f93Udy"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOG4Tta3mETo"
      },
      "source": [
        "### Unzip dataset from Google Drive to Colab's disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bunXNlW4XjF"
      },
      "source": [
        "!ls content/MyDrive\n",
        "!unzip content/MyDrive/skull_dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HGkkugemQKJ"
      },
      "source": [
        "### Install tensorflow-gpu 2.3.0\n",
        "The same tensorflow, that's listed in Conda environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj93pMnk474o"
      },
      "source": [
        "!pip install -U tensorflow-gpu==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaT12nEU5BEY"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmlSXtnPmgHZ"
      },
      "source": [
        "### Install segmentation_models library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyh_FGhe62Nt"
      },
      "source": [
        "# https://github.com/qubvel/segmentation_models/issues/374#issuecomment-672694688\n",
        "%env SM_FRAMEWORK=tf.keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyFmoCAj6Dt-"
      },
      "source": [
        "pip install segmentation-models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rFyfFUnmje-"
      },
      "source": [
        "### Data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLTByb1n536J"
      },
      "source": [
        "from segmentation_models import get_preprocessing\n",
        "\n",
        "\n",
        "def scans_generator(scans_train_directory_path: Path, scans_val_directory_path: Path, batch_size=16,\n",
        "                    target_size=(256, 256), shuffle=True, backbone=\"efficientnetb0\"):\n",
        "    \"\"\"\n",
        "    Tensorflow dataset generator.\n",
        "\n",
        "    :param scans_train_directory_path: It should contain one subdirectory per class. Any PNG, JPG, BMP, PPM or TIF\n",
        "    images inside each of the subdirectories directory tree will be included in the generator.\n",
        "    :param scans_val_directory_path: It should contain one subdirectory per class. Any PNG, JPG, BMP, PPM or TIF\n",
        "    images inside each of the subdirectories directory tree will be included in the generator.\n",
        "    :param backbone: backbone name of network you will use\n",
        "    :param shuffle: Whether to shuffle the data (default: True) If set to False, sorts the data in alphanumeric order.\n",
        "    :param target_size: The dimensions to which all images found will be resized.\n",
        "    :param batch_size: Size of the batches of data\n",
        "    :return train_combined_generator: A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing\n",
        "    a batch of images with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels\n",
        "    :return val_combined_generator: A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing\n",
        "    a batch of images with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels\n",
        "    :return train_samples: number of training samples in dataset\n",
        "    :return val_samples: number of validation samples in dataset\n",
        "    \"\"\"\n",
        "\n",
        "    # Preprocess image based on backbone implementation\n",
        "    preprocess_input = get_preprocessing(backbone)\n",
        "\n",
        "    images_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        # rescale=1/255, # -> Uncomment if not using preprocess_input\n",
        "        preprocessing_function=preprocess_input\n",
        "    )\n",
        "\n",
        "    masks_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "    train_images_generator = images_datagen.flow_from_directory(directory=scans_train_directory_path / \"scans\",\n",
        "                                                                target_size=target_size,\n",
        "                                                                batch_size=batch_size,\n",
        "                                                                seed=42,\n",
        "                                                                shuffle=shuffle,\n",
        "                                                                class_mode=None,\n",
        "                                                                interpolation=\"bilinear\",\n",
        "                                                                )\n",
        "\n",
        "    train_masks_generator = masks_datagen.flow_from_directory(directory=scans_train_directory_path / \"labels\",\n",
        "                                                              target_size=target_size,\n",
        "                                                              batch_size=batch_size,\n",
        "                                                              seed=42,\n",
        "                                                              shuffle=True,\n",
        "                                                              class_mode=None,\n",
        "                                                              interpolation=\"nearest\",\n",
        "                                                              )\n",
        "\n",
        "    val_images_generator = images_datagen.flow_from_directory(directory=scans_val_directory_path / \"scans\",\n",
        "                                                              target_size=target_size,\n",
        "                                                              batch_size=batch_size,\n",
        "                                                              seed=42,\n",
        "                                                              shuffle=shuffle,\n",
        "                                                              class_mode=None,\n",
        "                                                              interpolation=\"bilinear\",\n",
        "                                                              )\n",
        "\n",
        "    val_masks_generator = masks_datagen.flow_from_directory(directory=scans_val_directory_path / \"labels\",\n",
        "                                                            target_size=target_size,\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            seed=42,\n",
        "                                                            shuffle=True,\n",
        "                                                            class_mode=None,\n",
        "                                                            interpolation=\"nearest\",\n",
        "                                                            )\n",
        "\n",
        "    train_combined_generator = zip(train_images_generator, train_masks_generator)\n",
        "    val_combined_generator = zip(val_images_generator, val_masks_generator)\n",
        "\n",
        "    train_samples = train_images_generator.n\n",
        "    val_samples = val_images_generator.n\n",
        "\n",
        "    return train_combined_generator, val_combined_generator, train_samples, val_samples\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6DYzaMomq3R"
      },
      "source": [
        "### Getting Unet model from segmentation_models library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9U9n_Z07BTa"
      },
      "source": [
        "from segmentation_models import Unet\n",
        "\n",
        "\n",
        "def get_unet_model(backbone=\"efficientnetb0\", classes=1, activation=\"sigmoid\", encoder_weights=\"imagenet\"):\n",
        "    \"\"\"\n",
        "    Returns Unet model based on input variables\n",
        "\n",
        "    :param backbone: Unet backbone\n",
        "    :param classes: Number of classes\n",
        "    :param activation: Activation function\n",
        "    :param encoder_weights: Encoder weights\n",
        "    :return model: Model based on input variables\n",
        "    \"\"\"\n",
        "    model = Unet(backbone, classes=classes, activation=activation, encoder_weights=encoder_weights)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GgKyszymzMA"
      },
      "source": [
        "### Training input parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3ehtNk5wbQ"
      },
      "source": [
        "train_path = Path(\"skull_dataset/train/x\")\n",
        "val_path = Path(\"skull_dataset/val/x\")\n",
        "\n",
        "backbone = \"efficientnetb0\"\n",
        "\n",
        "batch_size = 32\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6yXO9wsm_eh"
      },
      "source": [
        "### Loss and Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-BjwId6i7uE"
      },
      "source": [
        "import segmentation_models as sm\n",
        "from segmentation_models.losses import dice_loss\n",
        "metrics = [sm.metrics.FScore(threshold=0.5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uowNeWbxnGJM"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nz9l3_V7jif"
      },
      "source": [
        "train_generator, val_generator, train_samples, val_samples = scans_generator(train_path,\n",
        "                                                                                val_path,\n",
        "                                                                                backbone=backbone,\n",
        "                                                                                batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwWrEjwo7Mak"
      },
      "source": [
        "model = get_unet_model(backbone=backbone, classes=1, activation=\"sigmoid\", encoder_weights=\"imagenet\")\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
        "    loss=dice_loss,\n",
        "    metrics=[metrics]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_f1-score\",\n",
        "        patience=2,\n",
        "        verbose=1,\n",
        "        mode=\"max\"\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        monitor=\"val_f1-score\",\n",
        "        save_best_only=1,\n",
        "        verbose=1,\n",
        "        mode=\"max\",\n",
        "        filepath=\"model_{epoch}\"\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_f1-score\",\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        mode=\"max\"\n",
        "    )\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF5xyCQ47Put"
      },
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_samples//batch_size,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_samples//batch_size*2,\n",
        "    callbacks=callbacks,\n",
        "    epochs=20,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}